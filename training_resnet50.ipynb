{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik do treningu modelu resnet50\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from functions import calculate_metrics\n",
    "\n",
    "MODEL_NAME = 'resnet50'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzenie folderów na output\n",
    "time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "model_output_path = MODEL_NAME + \"_\" + time\n",
    "os.makedirs(f\"models/{MODEL_NAME}_{time}\", exist_ok=True)\n",
    "os.makedirs(f\"models/{MODEL_NAME}_{time}/score\", exist_ok=True)\n",
    "os.makedirs(f\"models/{model_output_path}\", exist_ok=True)\n",
    "\n",
    "# wybór datasetu\n",
    "source_dir = 'data/for_test_split'\n",
    "# source_dir = 'data/2019_images_split'\n",
    "# source_dir = 'data/2015_2019_split'\n",
    "\n",
    "train_csv = source_dir + '/train.csv'\n",
    "train_dir = source_dir + '/train_images'\n",
    "validation_csv = source_dir + '/validation.csv'\n",
    "validation_dir = source_dir + '/validation_images'\n",
    "test_csv = source_dir + '/test.csv'\n",
    "test_dir = source_dir + '/test_images'\n",
    "\n",
    "# utworzenie datasetów\n",
    "class RetinaDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, shuffle=False):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "\n",
    "        if shuffle:\n",
    "            self.labels_df = self.labels_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0] + '.png')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = int(self.labels_df.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# transformacje i augmenacje\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.1,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "train_dataset = RetinaDataset(csv_file=train_csv, root_dir=train_dir, transform=train_transform, shuffle=True)\n",
    "validation_dataset = RetinaDataset(csv_file=validation_csv, root_dir=validation_dir, transform=val_test_transform, shuffle=True)\n",
    "test_dataset = RetinaDataset(csv_file=test_csv, root_dir=test_dir, transform=val_test_transform, shuffle=True)\n",
    "\n",
    "# ważenie klas\n",
    "labels = [label for _, label in train_dataset]\n",
    "class_counts = Counter(labels)\n",
    "class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(\"Wagi klas: \")\n",
    "for cls, weight in class_weights.items():\n",
    "    print(f\"{cls} : {weight:.4f}\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# zamrożenie parametrów\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# zmiana warstwy klasyfikującej\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs, 5))\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Dostępne urządzenie: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6692bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "num_epochs = NUM_EPOCHS\n",
    "patience = PATIENCE\n",
    "\n",
    "num_epochs_plot = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    num_epochs_plot += 1\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train, total_train = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    correct_val, total_val = 0, 0\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_running_loss / len(validation_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # zapis modelu po każdej epoce\n",
    "    # torch.save(model, f\"models/{model_output_path}/{model_output_path}_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    # early stopping i zapis\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # epochs_without_improvement = 0\n",
    "        torch.save(model, f\"models/{model_output_path}/{model_output_path}_best_val_acc.pth\")\n",
    "    # else:\n",
    "    #     epochs_without_improvement += 1\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model, f\"models/{model_output_path}/{model_output_path}_best_val_loss.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1} as validation loss did not improve.\")\n",
    "        break\n",
    "\n",
    "torch.save(model, f\"models/{model_output_path}/{model_output_path}_last_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocena modelu\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100 * np.mean(np.array(y_true) == np.array(y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "epochs_range = range(1, num_epochs_plot + 1)\n",
    "\n",
    "# funkcja straty\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(epochs_range, train_losses, label=\"Zbiór treningowy\")\n",
    "plt.plot(epochs_range, val_losses, label=\"Zbiór walidacyjny\")\n",
    "plt.xlabel(\"Liczba epok\")\n",
    "plt.ylabel(\"Funkcja straty\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.savefig(f\"models/{model_output_path}/score/funkcja_straty_{model_output_path}.png\")\n",
    "plt.show()\n",
    "\n",
    "# skuteczność\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(epochs_range, train_accuracies, label=\"Zbiór treningowy\")\n",
    "plt.plot(epochs_range, val_accuracies, label=\"Zbiór walidacyjny\")\n",
    "plt.axhline(y=test_accuracy, color='m', linestyle='--', label=f\"Zbiór testowy: {test_accuracy:.2f}%\")\n",
    "plt.xlabel(\"Liczba epok\")\n",
    "plt.ylabel(\"Skuteczność [%]\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.savefig(f\"models/{model_output_path}/score/skutecznosc_{model_output_path}.png\")\n",
    "plt.show()\n",
    "\n",
    "# macierz pomyłek\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(5), yticklabels=range(5))\n",
    "plt.xlabel(\"Wartość predykcji\")\n",
    "plt.ylabel(\"Klasa prawdziwa\")\n",
    "plt.title(\"Macierz pomyłek\")\n",
    "plt.savefig(f\"models/{model_output_path}/score/macierz_pomylek_{model_output_path}.png\")\n",
    "plt.show()\n",
    "\n",
    "metrics = calculate_metrics(cm)\n",
    "print(metrics)\n",
    "\n",
    "for class_label, scores in metrics.items():\n",
    "    print(f\"{class_label}: {scores}\")\n",
    "\n",
    "# zapis metryk\n",
    "df = pd.DataFrame(metrics).T\n",
    "df.to_csv(f\"models/{model_output_path}/score/metryki_{model_output_path}.csv\", index=False)\n",
    "\n",
    "# zapis loss i acc\n",
    "with open(f\"models/{model_output_path}/score/metryki_2_{model_output_path}.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Funkcja straty - dane treningowe (train_losses)', 'Funkcja straty - dane walidacyjne (val_losses)',\n",
    "                     'Skuteczność - dane treningowe (train_accuracies)', 'Skuteczność - dane walidacyjne val_accuracies'])\n",
    "    \n",
    "    for i in range(len(train_losses)):\n",
    "        writer.writerow([\n",
    "            train_losses[i],\n",
    "            val_losses[i],\n",
    "            train_accuracies[i],\n",
    "            val_accuracies[i]\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
